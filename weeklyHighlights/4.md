# AI Compass前沿速览：可灵创意工坊、字节Coze Studio&Coze Loop、通义万相2.2 、智谱GLM-4.5、腾讯混元3D世界模型开源

**AI-Compass** 致力于构建最全面、最实用、最前沿的AI技术学习和实践生态，通过六大核心模块的系统化组织，为不同层次的学习者和开发者提供从完整学习路径。

* github地址：[AI-Compass👈：https://github.com/tingaicompass/AI-Compass](https://github.com/tingaicompass/AI-Compass)
* gitee地址：[AI-Compass👈：https://gitee.com/tingaicompass/ai-compass](https://gitee.com/tingaicompass/ai-compass)


🌟 如果本项目对您有所帮助，请为我们点亮一颗星！🌟

# 1.每周大新闻
## 灵动画布 – 可灵AI推出的AI创意工作台

可灵AI有新动态，一是在世界人工智能大会期间发布全新创意工作台功能“灵动画布”，二是推出可灵2.1模型。

![kuaishou.png](https://free.picui.cn/free/2025/07/29/6888b2c75a6de.png)

#### 灵动画布情况
- **功能特点**：支持最多5人协同创作，有一站式创作流程、一键导出等功能，具备无限可视化空间、智能创作辅助等优势。
- **使用方式**：可通过网页端官网或手机端APP使用，按创建画布、添加元素等步骤操作。
- **应用场景**：适用于图像与视频生成、教学演示动画、学生创意项目等。
#### 可灵2.1模型亮点
运动质量更高、视频更美更灵动、指令响应更好，给出了相关图片及图生视频示例。 

* https://app.klingai.com/cn/

## SeedEdit 3.0 – 字节跳动推出的图像编辑模型

SeedEdit 3.0 是字节跳动Seed团队推出的图像编辑模型，支持用自然语言指令实现对图像的快速、高质量编辑。模型依托强大的文生图模型 Seedream 3.0，能精准理解用户指令，完成包括风格转换、细节调整、文字修改、光影变化等多种复杂编辑任务。模型在保留图像主体和细节方面表现出色，支持高清图像处理，适用专业设计师、内容创作者和普通用户，极大地简化图像编辑流程，提升创作效率，目前模型已上线火山方舟正式开放。

SeedEdit 3.0的主要功能
* 精准区域编辑：支持精准锁定图像中的特定区域进行修改。
* 智能文字处理：自动识别并替换图像中的文字内容，同时匹配原图的字体、光影和风格，智能填充周围纹理，确保画面完整无痕。
* 光影与氛围调整：支持将黑夜变为白天、调整逆光、暖色调等光影效果，光影过渡自然，能营造出电影质感的画面。
* 风格转换：支持多种风格转换，如“毛毡风”“水彩风”“卡通风”等，用户用一句话指令能切换风格，满足不同创意需求。
* 高效操作：用户用简单的自然语言指令能完成图片编辑，无需复杂操作，单张图片处理时间仅需 10-15 秒，极大地提升创作效率。

项目官网：https://volcenginecn.com/
arXiv技术论文：https://arxiv.org/pdf/2506.05083



## SkyRouter – AI部署平台

SkyRouter 是面向 AI 模型的高性能平台，借助硬件和软件端到端优化，实现更快生成速度和更高吞吐量。通过全球分布式网络，提供低延迟用户体验。采用简单易用 API，无需管理复杂设施，有透明定价模式，适合各类用户。

#### 主要功能
具备高性能优化、全球分布式网络、简单易用 API、透明定价、快速扩展、高稳定性等特点，还有 Playground 环境供用户测试探索模型。

#### 应用场景
可用于 AI Agent 协作平台、垂直 AI Agents、物联网智能中心。

#### 数据表现
能解锁 150 + 模型，平均月处理 2.2T 令牌，有 100 + 全球供应商，令牌处理速度达 600 每秒。 

* https://www.skyrouter.ai/

## Seko-商汤AI短视频创作Agent

商汤科技推出全球首个创编一体的AI短视频创作Agent——Seko。

#### 主要功能
可根据用户创意完成视频全流程创作，包括策划与剧本创作、自然语言编辑、角色一致性控制、多模态内容生成等，还提供推荐主体与灵感广场。

#### 使用方法
访问官网注册登录，输入创意描述，点击生成，可编辑调整，最后导出成片。

#### 应用场景
适用于短视频创作、短剧制作、产品宣传、角色二创、知识科普等场景，降低创作门槛。 


* https://seko.sensetime.com/explore


## AnyVoice – AI声音克隆平台

AnyVoice是全球首创的AI声音克隆平台，仅需3秒音频就能克隆出高度逼真声音，支持英、中、日、韩多语言。操作简单，无需技术专长，重视用户隐私。

#### 主要功能
3秒快速克隆声音，能捕捉说话者细微差别与情感，生成与真人难区分的音频；支持实时音频生成，克隆后可立即生成音频；生成的音频支持MP3或WAV格式下载。

#### 使用方法
访问官网https://anyvoice.net ，上传或录制3 - 10秒音频样本，点击“生成”，AI几秒内生成声音克隆，最后下载音频。

#### 产品定价
免费版适合个人非商业用途，每次最多200字符，每月1200秒音频生成，最多创建10个声音克隆模型；专业版适合商业用途，每次最多1000字符，无限生成，优先生成，可创建无限声音克隆模型。

#### 应用场景
涵盖内容创作、广告营销、教育与培训、游戏开发、虚拟助手等领域。 


## Opal – 谷歌推出的AI工作流生成平台

谷歌推出实验性AI工作流生成工具Opal，支持用自然语言和可视化编辑创建、分享AI小应用，无需代码构建多步骤AI应用。
#### 主要功能
可创建工作流，支持自然语言编辑和可视化编辑，能快速分享应用，还有预建模板库。
#### 使用方法
目前仅在美国公开测试，需访问官网注册登录，可选择模板或新建应用，描述逻辑生成工作流，再调整、测试和分享。
#### 应用场景
涵盖内容创作、数据分析、客户服务、教育学习、项目管理等领域。 


* https://opal.withgoogle.com/


## Agentar-Fin-R1 – 蚂蚁数科推出的金融推理大模型

蚂蚁数科推出面向金融领域的大型语言模型 Agentar - Fin - R1，基于 Qwen3 基础模型，有 8B 和 32B 参数版本，通过相关体系和框架优化，在金融及通用推理测试中表现出色。

![蚂蚁.png](https://free.picui.cn/free/2025/07/29/6888b2c300497.png)

#### 主要功能
具备复杂推理、决策支持、意图识别等功能，能保障金融系统安全和符合合规要求。

#### 技术原理
采用精细化金融任务标签体系、多维度可信度保障框架、加权训练框架、两阶段训练策略、归因循环机制等，提出创新评估基准 Finova。

#### 项目地址
arXiv 技术论文：https://arxiv.org/pdf/2507.16802 

#### 应用场景
可用于金融智能客服、风险评估与管理、市场趋势分析、财务报表分析、个性化推荐等。 



## Qwen-MT – 阿里机器翻译模型

Qwen - MT是阿里通义千问团队基于Qwen3架构推出的机器翻译模型，支持92种语言互译，覆盖全球超95%人口。

![qwen.png](https://free.picui.cn/free/2025/07/29/6888b2c8c29fa.png)

#### 主要功能
- 多语言支持：满足广泛跨语言需求。
- 高度定制化：可通过术语干预等功能自定义翻译风格。
- 低延迟与低成本：基于轻量级MoE架构，每百万输出token的API调用成本低至0.5美元。
- 高质量翻译：自动和人工评估表现出色。

#### 技术原理
基于Qwen3架构，用万亿级多语言和翻译数据训练，结合强化学习优化，采用轻量级MoE架构，支持定制化功能。

#### 翻译质量
自动评估中，在多领域翻译基准测试中显著优于可比规模模型；人工评估中，在十种主要语言翻译数据上表现优异。

#### 应用场景
涵盖跨语言内容创作、企业国际化、教育、法律政务、技术开发等领域。


* 项目官网：https://qwenlm.github.io/blog/qwen-mt/
* 在线体验 Demo：https://huggingface.co/spaces/Qwen/Qwen3-MT-Demo


## Runway Aleph – Runway推出的AI视频编辑模型

Runway Aleph 是 Runway 推出的强大的 AI 视频编辑模型。能通过简单的文字指令，快速实现视频内容的增删、风格转换、环境变换和镜头运动调整等功能。用户可以轻松移除视频中的多余元素，或者将白天场景变为夜晚，将视频风格从现实变为卡通。Aleph 的核心优势在于其基于上下文的编辑能力，能理解视频的叙事逻辑和时空关系，避免常见的编辑错误。


* 内容增删：能精准识别视频中的对象，支持添加新元素或移除不需要的内容。比如可以轻松去除玻璃反光或背景中的杂物，也可以在街头采访视频中加入飘落的樱花。
* 环境与氛围变换：用户可通过文本指令更改视频中的环境、天气或季节，像把晴天场景变为雨天，或将白天画面调整为夜景，赋予视频全新的叙事氛围。
* 风格迁移：支持将视频风格转换为卡通、油画或其他艺术风格，保持画面内容的一致性，为艺术创作和品牌宣传提供多样化选择。
* 镜头运动迁移：用户可保留原始视频的镜头运动方式，生成新的内容或视角，特别适合需要动态镜头效果的场景，比如模仿原视频的推拉摇移节奏生成新画面。
* 绿幕抠像与灯光优化：内置绿幕抠像功能，无需专业绿幕设备，AI 自动识别主体并抠图。支持重新打光，可根据场景需求自动调整光线效果。


# 2.每周项目推荐

## Coze Studio – 字节开源的AI Agent开发平台

#### 简介

Coze Studio（扣子空间）是一个由字节跳动开发并开源的一站式AI Agent开发平台。它提供可视化的工具，旨在简化AI Agent的创建、调试和部署过程，让用户无需编写代码即可快速构建和发布智能体，并支持将其部署到多种平台。

#### 核心功能

*   **可视化工作流构建：** 提供拖放节点的可视化画布，用于快速构建和编排复杂的业务逻辑或任务流程。
*   **Agent与应用开发：** 支持无代码方式开发AI Agent和应用程序，简化开发门槛。
*   **资源管理与集成：** 统一管理工作流、插件、数据库、知识库和变量等资源，并提供丰富的SDKs（如Python、JavaScript、Java） facilitating seamless integration.
*   **多平台发布：** 支持将构建的AI Agent和应用发布到不同的平台。
*   **专家Agent生态：** 提供预设或可定制的领域专家Agent，如用户研究专家、金融分析助手、舆情分析专家等，满足特定业务需求。
*   **智能任务拆解与工具调用：** Agent能够自动分析需求，拆解任务，并自主调用外部工具生成完整报告或完成复杂工作。

#### 技术原理

Coze Studio的核心技术原理在于其**可视化编程范式**与**模块化Agent架构**。它通过提供图形化的界面和可拖拽的节点，将复杂的AI逻辑和数据流抽象化，使得用户能够以非代码的方式构建AI Agent的工作流程。平台底层支持对**插件、知识库、数据库和变量**等多种资源的灵活管理和调用，实现Agent能力的扩展。此外，Coze Studio还提供了多种语言的SDKs，便于开发者通过API接口与平台进行交互和集成，将AI能力嵌入到现有应用中。其Agent设计理念强调任务的**自动化分析与执行**，通过内部逻辑编排和外部工具调用，实现复杂任务的自主完成。

![Snipaste_2025-07-29_19-29-37.png](https://free.picui.cn/free/2025/07/29/6888b2ca606e6.png)

#### 应用场景

*   **智能客服与对话机器人：** 快速构建企业内部或对外服务的智能客服，实现自动化问答和客户支持。
*   **数据分析与报告生成：** 开发能够自动分析特定领域数据（如市场调研、金融数据）并生成专业报告的Agent。
*   **内容创作与优化：** 用于生成SEO优化文章、营销文案等内容，提高内容生产效率。
*   **教育与研究助手：** 构建辅助学习、资料检索、论文撰写等方面的智能助手。
*   **业务流程自动化：** 将AI Agent应用于企业内部流程，如自动化任务分配、数据处理、信息汇总等，提升运营效率。
*   **行业专家系统：** 针对特定垂直领域（如医疗、法律、金融）开发具备专业知识和能力的AI Agent，提供专业咨询或辅助决策。


Github仓库：https://github.com/coze-dev/coze-studio


## Coze Loop – 字节Coze推出的AI Agent开发与调试平台

#### 简介
CozeLoop 是一个旨在简化与 Coze 平台交互的开发工具，通过提供多语言 SDK (如 Python、Go 和 JavaScript) 来帮助开发者构建、管理和监控基于 Coze 平台的 AI 应用。它专注于提升开发者在处理 AI 交互流程中的效率和可观测性。

![Snipaste_2025-07-29_19-29-11.png](https://free.picui.cn/free/2025/07/29/6888b2c9d539f.png)

#### 核心功能
*   **报告追踪 (Report Trace)**：允许开发者记录和报告 AI 应用的运行轨迹和关键事件，便于调试和性能分析。
*   **获取和格式化提示词 (Get and Format Prompt)**：提供从 CozeLoop 平台获取预定义或动态提示词（Prompt），并根据需要进行格式化的能力，简化 AI 模型输入准备工作。
*   **多语言支持**：提供 Python、Go、JavaScript 等多种主流编程语言的 SDK，便于不同技术栈的开发者集成。

#### 技术原理
CozeLoop 的技术原理主要基于客户端-服务端的交互模式。
*   **SDK 设计**：CozeLoop 为不同编程语言提供了轻量级的客户端开发工具包（SDK），这些 SDK 封装了与 CozeLoop 平台后端服务进行通信的 API 接口。
*   **分布式追踪 (Distributed Tracing)**：通过 SDK 提供的 `StartSpan` 和 `SetInput/SetOutput/Finish` 等方法，实现对 AI 交互流程中各个环节的追踪数据采集和上报，类似于 OpenTelemetry 等分布式追踪系统，用于监控和诊断。
*   **API 接口层**：SDK 通过 HTTP/RPC 等协议与 CozeLoop 后端服务进行通信，执行如提示词获取和追踪数据上传等操作。
*   **提示词管理**：后端平台负责存储和管理提示词模板，SDK 负责通过 `GetPrompt` 和 `PromptFormat` 方法根据业务逻辑获取并填充变量，生成最终的提示词。

#### 应用场景
*   **AI 应用开发**：开发者可以使用 CozeLoop SDK 快速将 AI 能力集成到现有的应用中，如构建智能客服、内容生成、自动化工作流等。
*   **AI Agent 监控与调试**：通过报告追踪功能，对复杂的 AI Agent 的决策路径和执行过程进行可视化监控和故障排查。
*   **提示词工程管理**：集中管理和版本控制提示词，便于团队协作和迭代优化 AI 模型的输入。
*   **跨平台集成**：利用不同语言的 SDK，在多种技术环境中（如后端服务、前端应用、数据分析脚本等）无缝对接 Coze 平台。



* Github仓库：https://github.com/coze-dev/cozeloop
* 官网地址：https://www.coze.cn/loop


## 扣子空间-网页设计功能上线

它旨在提供一个完整的、覆盖多种场景的设计解决方案，特别是针对招聘页、活动页和个人简历等具体应用。

#### 核心功能
*   **完整设计解决方案提供：** 针对特定页面（如招聘页、活动页、个人简历）提供一体化的设计支持。
*   **多场景覆盖：** 能够适应并应用于多种不同的业务或个人展示场景。

#### 技术原理
鉴于可用信息有限，无法深入解析具体技术原理。但推测其可能依赖于前端设计框架、UI/UX组件库，以及后端数据处理和内容生成技术，以实现高效且标准化的设计方案输出。

#### 应用场景
*   **企业招聘：** 用于快速生成和优化公司招聘页面。
*   **市场活动：** 辅助设计和部署各类线上或线下活动宣传页面。
*   **个人展示：** 帮助个人用户创建专业且富有吸引力的在线简历或个人主页。

* https://space.coze.cn/?from=landingpage



## 通义万相2.2 – 阿里开源AI视频生成模型

#### 简介
通义万相（Tongyi Wanxiang）是阿里云通义旗下的人工智能创意创作平台。其中，通义万相2.2（Wan2.2）是阿里巴巴开源的先进AI视频生成模型，旨在降低创意工作的门槛。该平台集成了多种AI生成能力，包括视频和图像内容的创作。

![通义.png](https://free.picui.cn/free/2025/07/29/6888b2c857b67.png)

![通义1.png](https://free.picui.cn/free/2025/07/29/6888b2c23803a.png)


#### 核心功能
*   **文生视频（Text-to-Video, T2V）**: 根据文本描述生成视频内容。
*   **图生视频（Image-to-Video, I2V）**: 根据静态图片生成动态视频。
*   **统一视频生成（Unified Video Generation, IT2V）**: 整合文本和图像输入进行视频生成。
*   **图像生成**: 支持文生图、图生图、涂鸦作画、虚拟模特、个人写真等多种图像创作模式。
*   **高级特效与LoRA训练**: 提供增强的图像/视频生成效果和更智能的LoRA模型训练功能。
*   **电影级控制**: 首次实现MoE架构的视频生成模型，具备电影级控制能力。

![通义2.png](https://free.picui.cn/free/2025/07/29/6888b2c2e4673.png)

#### 技术原理
通义万相2.2基于先进的AI视频生成模型，采用大规模模型（Large-Scale Video Generative Models）和混合专家架构（MoE-Architecture）来提升视频生成质量和控制力。其核心技术可能包括深度学习、扩散模型（如Hugging Face上提及的Diffusers）以及复杂的神经网络结构，以实现从文本或图像到高质量视频的转换。

#### 应用场景
*   **内容创作**: 为电影、广告、短视频等领域的创作者提供高效的视频和图像生成工具，降低制作成本和时间。
*   **数字营销**: 快速生成个性化、吸引人的宣传视频和图片，用于产品推广和品牌建设。
*   **艺术设计**: 辅助艺术家和设计师进行概念验证和视觉化创作，拓宽创意边界。
*   **个人娱乐**: 满足普通用户生成有趣视频和图片的个性化需求，如社交媒体分享等。
*   **教育与培训**: 制作教学动画、演示视频，提升学习体验。

* https://tongyi.aliyun.com/wanxiang/welcome
* https://github.com/Wan-Video/Wan2.2
* https://tongyi.aliyun.com/wanxiang

## GLM-4.5 –SOTA 模型

#### 简介
GLM-4.5是智谱AI（Z.ai）推出的一款新一代旗舰级开源大模型，旨在原生融合推理、代码和智能体（Agent）能力，是业界首款专注于智能体应用的SOTA模型。它在多个评测基准中表现卓越，综合性能达到开源模型的顶尖水平，尤其在代码智能体场景中表现优异。



![智谱.png](https://free.picui.cn/free/2025/07/29/6888b2c5ed9de.png)

#### 核心功能
*   **推理能力：** 提供强大的逻辑推理能力，能够处理复杂任务并进行深度思考。
*   **代码生成与理解：** 具备出色的代码智能，支持代码的生成、理解、调试和优化。
*   **智能体能力：** 专为构建和驱动智能体设计，能够作为核心驱动力，实现自主规划与执行。
*   **多版本支持：** 包含GLM-4.5（3550亿参数）和GLM-4.5-Air（1060亿参数）等版本，兼顾性能与效率。
*   **混合推理模式：** 支持“思考模式”和“非思考模式”，以适应复杂任务与即时响应的不同需求。

#### 技术原理
GLM-4.5采用先进的混合专家（MoE）架构，通过激活部分专家模型来高效处理任务。例如，GLM-4.5拥有3550亿总参数和320亿激活参数，而GLM-4.5-Air则更为紧凑，拥有1060亿总参数和120亿激活参数。模型在参数效率上实现了显著优化，在保持高性能的同时，参数量远低于同级别模型。其技术栈支持深度思考（Deep Thinking）、流式输出（Streaming Output）、函数调用（Function Call）、上下文缓存（Context Caching）和结构化输出（Structured Output）等高级功能，提升了模型的实用性和集成能力。

#### 应用场景
*   **AI智能体开发：** 作为核心驱动引擎，用于构建具备自主决策、规划和执行能力的各种智能体应用。
*   **自动化编程与开发辅助：** 辅助开发者进行代码生成、错误排查、代码重构等，提高开发效率。
*   **复杂问题推理：** 在金融分析、科学研究、医疗诊断等需要复杂逻辑推理的领域提供智能支持。
*   **企业级AI解决方案：** 适用于需要高性能、高效率和高可靠性AI模型的企业级应用场景。
*   **对话系统与智能助手：** 提升对话机器人、虚拟助手在理解、响应和执行复杂指令方面的能力。


* GitHub仓库：https://github.com/zai-org/GLM-4.5
* HuggingFace仓库： https://huggingface.co/collections/zai-org/glm-45-687c621d34bda8c9e4bf503b
* ModelScope仓库：https://modelscope.cn/collections/GLM-45-b8693e2a08984f
体验地址：
* HuggingFace： https://huggingface.co/spaces/zai-org/GLM-4.5-Space
* ModelScope：https://modelscope.cn/studios/ZhipuAI/GLM-4.5-Demo


## 腾讯混元3D世界模型开源

#### 简介
Hunyuan3D是腾讯研发的大规模三维生成模型，基于先进的扩散（Diffusion）技术。它能够通过文本描述或图像输入，快速、高效地生成高质量、逼真的3D资产。HunyuanWorld-1.0作为其重要组成部分，更是首个开源的三维世界生成模型，旨在革新3D内容创作流程。

![腾讯.png](https://free.picui.cn/free/2025/07/29/6888b2c534813.png)

#### 核心功能
*   **文本到三维生成 (Text-to-3D Generation)**：依据自然语言描述直接生成多样化的3D模型，涵盖物体、角色、环境等。
*   **图像到三维重建 (Image-to-3D Reconstruction)**：将2D图像转换为具有精确几何和纹理的高质量3D模型。
*   **高分辨率与高质量输出 (High-Resolution & High-Quality Output)**：生成细节丰富、视觉效果出众的3D资产。
*   **多视图生成与重建 (Multi-view Generation & Reconstruction)**：支持从多角度图像输入进行3D模型的生成与精细重建。
*   **场景与世界生成 (Scene & World Generation)**：尤其通过HunyuanWorld-1.0，实现复杂三维场景乃至整个虚拟世界的自动化生成。

#### 技术原理
Hunyuan3D的核心技术是**扩散模型 (Diffusion Models)**，这是一种生成式AI模型，通过逐步去噪过程从随机噪声中学习数据分布并生成新样本。其架构包含：
*   **文本编码器 (Text Encoders)**：负责将输入的文本描述转换为高维语义特征。
*   **图像编码器 (Image Encoders)**：处理输入的2D图像，提取视觉特征。
*   **扩散模型 (Diffusion Models)**：接收编码后的文本或图像特征，通过多步迭代逆向扩散过程，逐步从噪声中恢复并生成3D的潜在表示。
*   **3D解码器 (3D Decoders)**：将扩散模型输出的3D潜在表示解码为最终的3D几何（如网格或体素）和纹理信息，完成从2D/文本到3D的映射。
整个系统通过大规模3D数据集进行训练，以确保生成内容的质量和多样性。

#### 应用场景
*   **游戏开发 (Game Development)**：快速生成游戏角色、道具、场景环境，显著提升内容创作效率。
*   **影视动画制作 (Film & Animation Production)**：辅助制作复杂的3D场景、特效及角色，降低生产成本和周期。
*   **虚拟现实 (VR) 与增强现实 (AR)**：为VR/AR应用提供丰富的3D内容库，构建沉浸式体验。
*   **数字内容创作 (Digital Content Creation)**：赋能设计师、艺术家和内容创作者，快速实现3D视觉创意。
*   **元宇宙构建 (Metaverse Construction)**：大规模生成虚拟世界的3D资产和环境，加速元宇宙生态的建设。
*   **产品设计与可视化 (Product Design & Visualization)**：将概念图或文本描述迅速转化为3D模型进行展示、原型制作和评估。


腾讯混元 3D 世界模型 1.0：

* 项目主页：https://3d-models.hunyuan.tencent.com/world/

* 体验地址：https://3d.hunyuan.tencent.com/sceneTo3D

* Hugging Face 模型地址：https://huggingface.co/tencent/HunyuanWorld-1

* Github 项目地址：https://github.com/Tencent-Hunyuan/HunyuanWorld-1.0


## 书生浦语-科学多模态大模型Intern-S1

#### 简介
Intern-S1 是上海人工智能实验室 (Shanghai AI Laboratory) 开发的 InternLM 系列大型语言模型 (LLM) 中的一员。它旨在提供高质量的语言模型和全栈工具链，尤其强调其强大的推理能力和与外部工具的交互能力。

#### 核心功能
*   **工具调用 (Tool Calling)**：能够调用外部工具，例如获取实时信息、执行代码或调用其他应用程序内的函数，从而扩展模型的能力边界。
*   **思维模式 (Thinking Mode)**：默认开启的思维模式显著增强了模型的推理能力，使其能够生成更高质量的响应。此模式可根据需要进行配置。
*   **多模态能力 (Multimodal Capabilities)**：支持多模态输入，进一步拓宽了模型的应用范围。

#### 技术原理
Intern-S1 基于 InternLM 的基础架构，并在此基础上进行了优化：
*   **函数调用集成**：通过特定的工具调用机制，模型能够解析用户意图并自动选择、调用外部函数或API，将外部世界的信息和能力整合到其响应生成过程中。
*   **FP8 量化**：提供 FP8 (8位浮点) 量化版本，这意味着模型在保持较高性能的同时，大幅降低了显存占用和计算资源需求，提高了推理效率。
*   **高级推理机制**：内置“思维模式”，通过引导模型进行类似人类的逐步思考过程，提升其复杂问题的推理和解决能力。
*   **部署灵活性**：支持通过 SGLang 和 Ollama 等多种方式进行本地部署，为开发者和研究人员提供了便捷的实验和应用环境。

#### 应用场景
*   **智能代理 (AI Agents)**：构建能够自主获取最新信息、执行复杂任务或与外部系统交互的智能代理。
*   **代码辅助与自动化**：在软件开发中，辅助代码生成、调试，或自动化某些编程任务。
*   **实时信息查询**：结合外部搜索引擎或数据库，提供即时、准确的信息服务。
*   **复杂问题解决**：在需要多步推理和外部工具协助的领域（如科学计算、金融分析）提供解决方案。
*   **大模型研究与开发**：作为开放的模型和工具链，为研究人员和开发者提供强大的基础模型和开发平台，用于探索新的应用和优化。


* Github仓库：https://github.com/InternLM/Intern-S1
* HuggingFace模型库：https://huggingface.co/internlm/Intern-S1-FP8
* 官网：https://intern-ai.org.cn/home



## Step 3 – 阶跃星辰多模态推理模型

#### 简介
Step 3 是阶跃星辰（StepFun AI）发布的新一代基础大模型，专为推理时代设计。它集高性能与极致成本效益于一体，具备强大的视觉感知和复杂推理能力，旨在成为SOTA（State-of-the-Art）水平的开放生态基础模型。

#### 核心功能
*   **多模态感知与理解：** 具备强大的视觉感知能力，能处理和理解多种模态的信息。
*   **复杂推理：** 针对推理时代的需求，擅长进行复杂的逻辑推理。
*   **高性能与高效率：** 在保证卓越性能的同时，注重极致的成本效益。
*   **开放生态支持：** 作为开放模型，支持开发者和研究人员在其基础上进行创新。

#### 技术原理
Step 3 采用了先进的**MoE（Mixture-of-Experts）架构**，这使得模型能够在大参数量下实现高效的激活参数量，从而平衡性能与计算资源消耗。总参数量达到321B，激活参数量为38B。这种架构有助于模型在不同任务上动态激活最相关的专家网络，优化资源利用和推理效率。其技术报告进一步详细阐述了Attention-FFN解耦等优化技术，以实现高吞吐量解码。

#### 应用场景
*   **智能助理与对话系统：** 提供更自然、智能的多模态交互体验。
*   **视觉内容理解与生成：** 应用于图像识别、视频分析、内容创作等领域。
*   **复杂问题解决：** 在科研、工程、医疗等需要强大推理能力的场景中提供辅助。
*   **开发者工具与平台：** 作为基础模型，可供开发者在其上构建各类AI应用和服务。

* https://mp.weixin.qq.com/s/SuAfRxg-GpTz_OIeDzd9-w

* Github仓库：https://github.com/stepfun-ai/Step3


## Higgs Audio V2 – 开源语音大模型

#### 简介
Higgs Audio V2是由李沐及其团队Boson AI开发并开源的语音大模型。它是一个强大的音频基础模型，经过超过1000万小时的音频数据和多样化文本数据的预训练，旨在模拟自然流畅的多人互动场景，并具备生成高质量音频的能力。

#### 核心功能
*   **多语言对话生成：** 能够生成自然流畅的多语言对话。
*   **自动韵律调整：** 自动匹配说话者的韵律和情感。
*   **语音克隆：** 具备语音克隆能力，可以复制特定人的声音。
*   **歌声合成：** 支持歌声合成功能。
*   **零样本文本到语音（Zero-shot TTS）：** 能够在没有特定训练数据的情况下，通过参考文本、参考音频和目标文本进行文本到语音的转换。
*   **多人对话生成：** 特别优化了模拟多人互动对话场景的能力。

#### 技术原理
Higgs Audio V2采用统一的音频语言建模方法（unified audio language modeling at scale）。它是一个基于超过1000万小时的音频数据和多样化文本数据进行预训练的音频基础模型。这种大规模的预训练使其能够捕捉复杂的语音特征、韵律变化以及多语言和多说话人的交互模式，从而实现自然度高、表现力强的语音生成。模型在多个基准测试中展现出高性能，包括Seed-TTS Eval、Emotional Speech Dataset (ESD)、EmergentTTS-Eval和Multi-speaker Eval。

#### 应用场景
*   **虚拟助手与客服系统：** 创建更自然、更具交互性的AI虚拟助手和智能客服。
*   **内容创作：** 用于播客、有声读物、游戏配音、动画等领域，快速生成高质量的语音和对话内容。
*   **教育与培训：** 制作多语言教学材料、模拟对话练习，提升学习体验。
*   **电影与电视制作：** 辅助角色配音，实现不同角色间的自然对话，甚至进行歌声合成。
*   **无障碍辅助：** 为有视力障碍的用户提供文本转语音服务，或为特定应用提供定制化语音交互。
*   **社交媒体与娱乐：** 生成个性化的音频内容，增强用户互动体验，如语音社交、虚拟偶像歌唱等。

* Github仓库：https://github.com/boson-ai/higgs-audio
* 在线体验Demo：https://huggingface.co/spaces/smola/higgs_audio_v2


## OceanBase PowerRAG – 一站式RAG应用开发工具

#### 简介
OceanBase PowerRAG 是一款由 OceanBase 推出的开箱即用、一站式检索增强生成（RAG）应用开发工具。它旨在简化并加速智能应用的开发与上线，打通了RAG应用从数据层、模型层到应用层的全流程，无需复杂的部署和配置，支持将RAG能力无缝集成到各类现有系统中。

#### 核心功能
*   **文档存储与拆分：** 支持用户上传各类文档（如手册、邮件、代码库等），并自动进行智能文本切分处理，将内容拆分为适合检索和处理的片段。
*   **向量化嵌入：** 将拆分后的文档片段转换为向量形式，为后续高效的相似性检索提供基础。
*   **向量检索：** 基于向量化嵌入的结果，提供高效的向量检索能力，能够快速找到与用户输入最相似的文档片段。
*   **对话（Chat）功能：** 支持自然语言交互，用户通过对话方式提出问题，系统根据检索到的文档内容生成精准答案。
*   **API 高效调用：** 提供强大的API接口，支持与各类系统无缝集成，便于用户快速构建RAG应用。

#### 技术原理
OceanBase PowerRAG 的核心技术原理是**检索增强生成 (RAG)**。它首先通过**智能文本切分技术**对上传的文档进行预处理，将非结构化或半结构化的文本数据转换为可管理的片段。接着，这些文本片段被**向量化嵌入**，即转换为高维向量空间中的数值表示，使得语义相似的文本片段在向量空间中距离更近。当用户提出查询时，系统会执行**向量检索**，在预先嵌入的知识库中快速找到与查询语义最相关的文档片段。最后，这些检索到的相关信息会被作为上下文输入给大型语言模型（LLM），从而生成**精准且有依据的答案**。整个过程实现了知识库的动态更新和高效利用，确保了生成内容的准确性和时效性。

#### 应用场景
*   **知识管理：** 员工通过自然语言提问，系统检索企业内部文档（如手册、邮件、代码库等），生成精准答案，提升工作效率。
*   **企业客服：** 根据用户查询，系统实时检索产品文档、FAQ 或政策，生成具体且上下文相关的回复，提高解决效率并减轻人工客服负担。
*   **智能问答：** 回答用户开放域问题，通过实时检索最新或特定知识库信息，生成准确且有依据的答案。
*   **研究与信息分析：** 辅助研究人员快速检索相关文献、数据集或新闻，整合信息并生成综述、分析报告或背景资料，加速调研过程。
*   **专业决策辅助：** 在特定领域（如金融、医疗等）为专业人士提供快速、准确的信息支持，辅助决策。


* 官网：https://www.oceanbase.com/product/powerrag

## SuperDesign – 开源AI设计Agent
#### 简介
SuperDesign是一款开源AI设计Agent，旨在帮助设计师和开发者在集成开发环境（IDE）中直接生成UI原型、组件和线框图。它通过自然语言输入驱动设计过程，并能够并行生成多个设计选项，大幅提升设计迭代效率。

![design.png](https://free.picui.cn/free/2025/07/29/6888b2c77eac4.png)

#### 核心功能
*   **AI驱动的UI生成：** 能够根据自然语言描述，自动生成UI原型、组件和线框图。
*   **多方案并行生成：** 支持同时生成并展示多个设计方案，方便用户进行对比和选择。
*   **IDE集成：** 作为IDE（如Cursor, Windsurf）的扩展，允许设计师和开发者在熟悉的工作环境中进行设计操作。
*   **设计迭代与变体创建：** 用户可以轻松地基于现有设计进行分叉（fork）并创建多种变体。

#### 技术原理
SuperDesign的核心技术基于大型语言模型（LLM）和多Agent系统。它可能采用了Qwen3等基础模型进行开发，通过自然语言处理（NLP）技术解析用户输入的设计需求。其“并行生成多个设计选项”的功能，暗示了内部可能运行着多个独立的AI Agent，每个Agent负责探索不同的设计空间或基于不同的参数生成方案。这种多Agent协作模式结合无限画布（infinite canva UX）的交互方式，使得设计过程更具探索性和灵活性。项目开源，允许用户自定义Agent和迭代设计流程。

#### 应用场景
*   **产品原型快速构建：** 适用于需要快速验证设计概念的产品经理和UI/UX设计师。
*   **前端开发辅助：** 开发者可以直接在IDE中生成UI组件和布局，加速前端开发流程。
*   **设计探索与创意激发：** 通过并行生成多个设计选项，帮助设计师打破思维定式，探索更多可能性。
*   **教育与研究：** 作为开源项目，可用于AI设计Agent领域的研究和教学。

* 项目官网：https://www.superdesign.dev/
* GitHub仓库：https://github.com/superdesigndev/superdesign


## MonkeyCode – 开源本地AI编程助手

#### 简介
MonkeyCode 是长亭科技推出的一款企业级智能编程辅助平台。它专为研发管理设计，支持私有化部署、离线使用，并兼容第三方及本地化大语言模型。MonkeyCode 旨在通过 AI 能力提升研发效率，同时保障代码质量和数据安全，为企业提供远超普通AI编程助手的综合解决方案。

![Snipaste_2025-07-29_19-36-57.png](https://free.picui.cn/free/2025/07/29/6888b2cbed3d9.png)

#### 核心功能
*   **智能代码辅助**: 提供代码补全、自然语言编程等功能，加速开发流程。
*   **代码安全扫描**: 集成代码安全扫描能力，在编程过程中发现并规避潜在安全风险。
*   **企业级管理面板**: 提供强大的管理和审计功能，实现对AI编程行为的严格管控和合规性要求。
*   **私有化部署与离线支持**: 允许企业将平台部署在内部环境中，确保代码和数据的隐私性与安全性，并支持无网络环境使用。
*   **大模型兼容性**: 灵活兼容各类第三方及本地化大语言模型，满足不同企业的技术栈和定制需求。

#### 技术原理
MonkeyCode 的客户端插件部分基于 Roo Code 开发，并在此基础上进行了功能增强与用户体验优化。其核心技术原理在于利用先进的 AI 大语言模型（LLM）进行代码的智能生成、补全、分析与安全检测。通过私有化部署，确保了企业敏感代码和数据在本地环境中处理，避免数据外泄风险。平台通过集成AI模型，能够实时对编程行为进行分析、辅助和审计，实现高效且安全的软件开发生命周期管理。

#### 应用场景
*   **高安全需求企业**: 适用于对代码安全、数据隐私有严格要求的金融、政务、军工等行业企业。
*   **内部研发效率提升**: 帮助大型企业或研发团队标准化和加速开发流程，提高整体生产力。
*   **代码质量管控**: 用于对代码规范性、健壮性和安全性有严格要求的场景，通过AI辅助进行质量把控。
*   **离线开发环境**: 适用于需要在无互联网连接或受限网络环境中进行开发的团队。
*   **大模型定制与集成**: 满足企业希望将自身训练的或特定大模型集成到开发工具链中的需求。

* 项目官网：https://monkeycode.docs.baizhi.cloud/welcome
* GitHub仓库：https://github.com/chaitin/MonkeyCode


## KAT-V1是快手开源的自动思考（AutoThink）大模型

#### 简介
KAT-V1（Kwaipilot-AutoThink）是快手开源的大型语言模型，旨在解决大型模型推理过程中“过度思考”的问题。该模型拥有40B和200B两种版本，创新性地融合了思考与非思考能力，使其能够根据问题的难度自适应地切换推理模式，从而在保持高性能的同时提升效率。其中，40B版本已展现出接近顶尖模型的优异性能。

#### 核心功能
*   **自适应思考模式切换：** KAT-V1能够根据输入问题的复杂程度，智能地判断并切换是否需要进行显式的“思维链”（Chain-of-Thought, CoT）推理，或直接给出答案。
*   **缓解过度思考：** 通过学习何时进行CoT以及何时直接响应，模型有效避免了不必要的中间推理步骤，提高了推理效率和响应速度。
*   **高性能文本生成：** 在数学、代码生成、常识推理等多个基准测试中，KAT-V1展现出卓越的性能表现。
*   **融合思考与非思考能力：** 模型内部集成了两种处理机制，使其能够灵活应对不同类型的任务需求。

#### 技术原理
KAT-V1的核心技术原理在于其独特的“Kwaipilot-AutoThink”架构和两阶段推理范式。
*   **Kwaipilot-AutoThink架构：** 该架构允许模型学习并控制何时生成显式的思维链（Chain-of-Thought），以及何时直接给出答案。这通常涉及到决策模块或一种策略学习机制。
*   **两阶段推理范式：** 模型首先会评估问题的复杂性和类型，然后决定是否激活CoT推理路径。对于需要复杂逻辑分解的问题，它会生成详细的中间步骤；对于简单或直接的问题，则快速生成结果。
*   **CoT与直接回答的动态平衡：** 通过在训练中优化这种平衡，模型旨在减少冗余计算，提升推理效率，同时不牺牲准确性。这可能涉及特定的损失函数设计和训练策略，以惩罚不必要的CoT生成。
*   **大规模语言模型基础：** 基于400亿（40B）和2000亿（200B）参数的强大Transformer架构，继承了大规模预训练模型的强大语言理解和生成能力。

#### 应用场景
*   **智能问答系统：** 能够更高效、准确地回答用户提问，尤其是在面对复杂问题时，可提供清晰的推理过程。
*   **代码辅助开发：** 在代码生成和调试场景中，根据需求提供逐步的解决方案或直接输出代码片段。
*   **数学问题求解：** 有效处理复杂的数学推理题，通过自适应思考模式提高解题效率和准确率。
*   **通用AI助手：** 作为多功能AI助手，在需要不同思考深度的任务中提供灵活、智能的响应。
*   **教育与研究：** 作为研究工具，探索大型模型如何更有效地进行推理，并为学生提供带有解释的解决方案。


* HuggingFace模型库：https://huggingface.co/Kwaipilot/KAT-V1-40B
* arXiv技术论文：https://arxiv.org/pdf/2507.08297

## Agent Lightning – 微软开源的Agent模型训练框架

Agent Lightning 是微软研究团队推出的灵活可扩展的智能Agent优化框架。框架能无缝集成到任何现有的Agent框架中（如 OpenAI Agents SDK、LangChain 等），基于强化学习等数据驱动技术对代理进行优化，提升其性能和适应性。Agent Lightning 支持多轮交互、多Agent协调和动态上下文管理等复杂场景，提供错误监控功能，确保优化过程的稳定性。Agent Lightning 通过解耦Agent开发逻辑与优化逻辑，实现无需修改代理代码进行模型训练的目标，为开发者提供强大的工具构建动态、学习型智能Agent


Agent Lightning的技术原理
* 架构设计：
  1. Lightning Server：管理训练数据，准备样本并提供 LLM（语言模型）端点。
  2. Lightning Client：Agent从服务器获取样本，处理样本（涉及与 LLM 交互），将结果（轨迹）返回给服务器。
  3. 非侵入式数据收集：基于 Sidecar 设计，非侵入式地监控 Agent 运行并收集数据（包括执行轨迹、错误和奖励信号）。
* 强化学习流程：Lightning Server 从任务池中拉取任务并发送给Agent尝试完成任务。收集的轨迹数据被转换为标准的转换元组（state, action, reward, next_state），用在训练。用强化学习算法（如 GRPO）更新模型，形成紧密的反馈循环。
* 解耦与灵活性：通过中间层将Agent框架与 RL 训练系统解耦，支持无缝集成和扩展。能使用多种优化方法（如提示调整、模型选择等），计划支持更多优化后端（如 LLaMA-Factory）和代理框架（如 Semantic Kernel）。

* 项目官网：https://www.microsoft.com/en-us/research/project/agent-lightning/
* GitHub仓库：https://github.com/microsoft/agent-lightning


## Eigent – CAMEL-AI推出的多智能体Workforce桌面应用

Eigent 是CAMEL-AI 团队推出的全球首个桌面端多智能体 Workforce 平台（Multi-agent Workforce）。平台基于开源项目 CAMEL 和 OWL 构建，支持用户自定义专属的 AI 团队，实现复杂任务的自动化。Eigent 具备多智能体并行执行、人类能随时介入（Human-in-the-loop）、灵活接入多种工具、100% 开源和本地部署等特点。Eigent 能将复杂的工作流程转化为自动化的任务，提升工作效率，同时保障数据隐私和可控性。

![Snipaste_2025-07-30_19-34-16.png](https://free.picui.cn/free/2025/07/30/688a0344664d5.png)

* Eigent的技术原理
多智能体系统架构：Eigent 的核心是多智能体系统，由多个智能体（Agent）组成，每个智能体都有特定的技能和工具。智能体通过协作完成复杂的任务。
Task Manager Agent：负责任务的拆解和分配策略。
Coordinator Agent：负责智能体之间的分工和协作。
Worker Nodes：具体的执行者，负责完成分配给它们的任务。
并行处理：Eigent 基于并行处理提升任务执行效率。任务被拆分为多个子任务，子任务能同时由不同的智能体执行，不是传统的单智能体串行执行方式。
动态任务拆分与重新规划：在任务执行过程中根据智能体的状态和任务的进展动态地拆分任务。如果某个智能体遇到问题或任务失败，系统自动重新规划任务，甚至创建新的智能体节点完成任务。



* 如何使用Eigent
  * 访问 Eigent 官网：访问 Eigent 官方网站： https://www.eigent.ai/，根据操作系统选择下载对应版本。
  * 登录账户：按提示完成注册和登录。
  * 创建任务：登录后，点击“Create New Task”，输入任务名称和描述。
  * 选择或自定义智能体：选择预定义的智能体或自定义智能体满足任务需求。
  * 配置任务参数：根据任务需求，输入关键词、上传文件或指定其他参数。
  * 启动任务：配置完成后，点击“Start Task”按钮启动任务。
  * 监控任务进度：在任务管理界面实时查看任务进度，必要时进行人为干预。
  * 查看任务结果：任务完成后，在任务管理界面查看详细结果。


* 项目官网：https://www.eigent.ai/
* GitHub仓库：https://github.com/eigent-ai/eigent

# 3. AI-Compass

**AI-Compass** 致力于构建最全面、最实用、最前沿的AI技术学习和实践生态，通过六大核心模块的系统化组织，为不同层次的学习者和开发者提供从完整学习路径。

* github地址：[AI-Compass👈：https://github.com/tingaicompass/AI-Compass](https://github.com/tingaicompass/AI-Compass)
* gitee地址：[AI-Compass👈：https://gitee.com/tingaicompass/ai-compass](https://gitee.com/tingaicompass/ai-compass)

<div align="center">
  <p>🌟 如果本项目对您有所帮助，请为我们点亮一颗星！🌟</p>
</div>

### 📋 核心模块架构：
- **🧠 基础知识模块**：涵盖AI导航工具、Prompt工程、LLM测评、语言模型、多模态模型等核心理论基础
- **⚙️ 技术框架模块**：包含Embedding模型、训练框架、推理部署、评估框架、RLHF等技术栈
- **🚀 应用实践模块**：聚焦RAG+workflow、Agent、GraphRAG、MCP+A2A等前沿应用架构
- **🛠️ 产品与工具模块**：整合AI应用、AI产品、竞赛资源等实战内容
- **🏢 企业开源模块**：汇集华为、腾讯、阿里、百度飞桨、Datawhale等企业级开源资源
- **🌐 社区与平台模块**：提供学习平台、技术文章、社区论坛等生态资源

### 📚 适用人群：
- **AI初学者**：提供系统化的学习路径和基础知识体系，快速建立AI技术认知框架
- **技术开发者**：深度技术资源和工程实践指南，提升AI项目开发和部署能力
- **产品经理**：AI产品设计方法论和市场案例分析，掌握AI产品化策略
- **研究人员**：前沿技术趋势和学术资源，拓展AI应用研究边界
- **企业团队**：完整的AI技术选型和落地方案，加速企业AI转型进程
- **求职者**：全面的面试准备资源和项目实战经验，提升AI领域竞争力