# 0.è˜‘è‡ä¹¦&çŒ«ä¹¦-å¼ºåŒ–å­¦ä¹ ä¹¦ç±

å¼ºåŒ–å­¦ä¹ æ¨¡å—æ„å»ºäº†ä»ç†è®ºå­¦ä¹ åˆ°é¡¹ç›®å®æˆ˜çš„å®Œæ•´RLæŠ€æœ¯ç”Ÿæ€ï¼Œä¸ºå¼ºåŒ–å­¦ä¹ ç ”ç©¶è€…å’Œå·¥ç¨‹å¸ˆæä¾›ç³»ç»ŸåŒ–çš„æ™ºèƒ½å†³ç­–è§£å†³æ–¹æ¡ˆã€‚è¯¥æ¨¡å—ç³»ç»Ÿæ€§åœ°æ•´ç†äº†è˜‘è‡ä¹¦ã€æ·±åº¦å¼ºåŒ–å­¦ä¹ åŸç†ä¸å®è·µç­‰ç»å…¸ç†è®ºæ•™æï¼Œä»¥åŠGoogle Dopamineã€Facebook ReAgentã€Rayã€DI-ENGINEã€ElegantRLã€MARLåº“ã€SLM Labã€Spinning Up in Deep RLã€Stable Baselines3ã€Tianshouç­‰10+ä¸ªä¸»æµå¼ºåŒ–å­¦ä¹ æ¡†æ¶å’Œå·¥å…·åº“ã€‚æŠ€æœ¯æ ˆæ¶µç›–äº†Unity ML-Agentså¼ºåŒ–å­¦ä¹ ç¯å¢ƒã€Gymnasiumæ¡ˆä¾‹åˆé›†ç­‰å®éªŒå¹³å°ï¼Œæ·±å…¥ä»‹ç»äº†Rainbowã€SACã€TD3ã€DDPGã€A2Cã€PPOç­‰å•æ™ºèƒ½ä½“ç®—æ³•ï¼Œä»¥åŠMADDPGã€QMIXç­‰å¤šæ™ºèƒ½ä½“ç®—æ³•çš„å®ç°åŸç†å’Œåº”ç”¨åœºæ™¯ã€‚æ¨¡å—è¯¦ç»†è§£æäº†ä»·å€¼å‡½æ•°é€¼è¿‘ã€ç­–ç•¥æ¢¯åº¦æ–¹æ³•ã€æ·±åº¦å¼ºåŒ–å­¦ä¹ ã€å¤šæ™ºèƒ½ä½“åä½œç­‰æ ¸å¿ƒæŠ€æœ¯ï¼Œä»¥åŠæ¢ç´¢ä¸åˆ©ç”¨å¹³è¡¡ã€æ ·æœ¬æ•ˆç‡ä¼˜åŒ–ã€è®­ç»ƒç¨³å®šæ€§ç­‰å…³é”®æŠ€æœ¯æŒ‘æˆ˜çš„è§£å†³æ–¹æ¡ˆã€‚å†…å®¹åŒ…æ‹¬ç¯å¢ƒå»ºæ¨¡ã€å¥–åŠ±è®¾è®¡ã€ç½‘ç»œæ¶æ„ã€è¶…å‚æ•°è°ƒä¼˜ç­‰å®Œæ•´çš„RLå¼€å‘æµç¨‹ï¼Œä»¥åŠåˆ†å¸ƒå¼è®­ç»ƒã€æ¨¡å‹éƒ¨ç½²ã€æ€§èƒ½è¯„ä¼°ç­‰å·¥ç¨‹åŒ–å®è·µæŠ€æœ¯ã€‚æ­¤å¤–ï¼Œè¿˜æä¾›äº†æ–—åœ°ä¸»AIã€ç‹è€…è£è€€AIã€è‚¡ç¥¨é‡åŒ–äº¤æ˜“ã€äº”å­æ£‹AIã€æ‰‘å…‹AIç­‰ä¸°å¯Œçš„é¡¹ç›®æ¡ˆä¾‹ï¼Œæ¶µç›–æ¸¸æˆAIã€é‡‘èé‡åŒ–ã€ç­–ç•¥åšå¼ˆç­‰å¤šä¸ªåº”ç”¨é¢†åŸŸï¼Œå¸®åŠ©å¼€å‘è€…æŒæ¡ä»ç®—æ³•ç ”ç©¶åˆ°äº§ä¸šåº”ç”¨çš„å®Œæ•´å¼ºåŒ–å­¦ä¹ æŠ€æœ¯æ ˆï¼Œå®ç°å¤æ‚å†³ç­–é—®é¢˜çš„æ™ºèƒ½åŒ–è§£å†³æ–¹æ¡ˆã€‚

- [å¼ºåŒ–å­¦ä¹ è˜‘è‡ä¹¦](https://datawhalechina.github.io/easy-rl/#/chapter1/chapter1)
- [æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼šåŸç†ä¸å®è·µ](https://github.com/chenzomi12/Deep-Reinforcement-Learning)

# å¼ºåŒ–å­¦ä¹ åº“æ¨è

- [å¼ºåŒ–å­¦ä¹ åº“åˆé›†](https://github.com/wwxFromTju/awesome-reinforcement-learning-lib)
- [google/dopamine: Dopamine is a research framework for fast prototyping of reinforcement learning algorithms.](https://github.com/google/dopamine/)
- [facebookresearch/ReAgent: A platform for Reasoning systems (Reinforcement Learning, Contextual Bandits, etc.)](https://github.com/facebookresearch/ReAgent/)
- [alex-petrenko/sample-factory: High throughput synchronous and asynchronous reinforcement learning](https://github.com/alex-petrenko/sample-factory)
- [astooke/rlpyt: Reinforcement Learning in PyTorch](https://github.com/astooke/rlpyt)
- [tensorlayer/TensorLayer: Deep Learning and Reinforcement Learning Library for Scientists and Engineers](https://github.com/tensorlayer/TensorLayer/)
- [pfnet/pfrl: PFRL: a PyTorch-based deep reinforcement learning library](https://github.com/pfnet/pfrl/)
- [rail-berkeley/rlkit: Collection of reinforcement learning algorithms](https://github.com/rail-berkeley/rlkit/)

------------------------------------------------------------

## 0.Pearl

- [facebookresearch/Pearl: A Production-ready Reinforcement Learning AI Agent Library brought by the Applied Reinforcement Learning team at Meta.](https://github.com/facebookresearch/pearl)

------------------------------------------------------------

## 0.RAY

- [RAYå…¥é—¨æŒ‡å— â€” Ray 2.1.0](https://docs.ray.io/en/latest/ray-overview/index.html)
- [Ray is a unified framework for scaling AI and Python applications. Ray consists of a core distributed runtime and a toolkit of libraries (Ray AIR) for accelerating ML workloads.](https://github.com/ray-project/ray/)

------------------------------------------------------------

## DI-ENGINE

- [æ¬¢è¿æ¥åˆ° DI-engine ä¸­æ–‡æ–‡æ¡£ â€” DI-engine 0.1.0 æ–‡æ¡£](https://di-engine-docs.readthedocs.io/zh_CN/latest/)
- [DI-engine-docs/index.rst at main Â· opendilab/DI-engine-docs](https://github.com/opendilab/DI-engine-docs/blob/main/source/index.rst)
- [opendilab/DI-engine: OpenDILab Decision AI Engine](https://github.com/opendilab/DI-engine/)

------------------------------------------------------------

## ElegantRL â€œå°é›…â€

- [ElegantRL â€œå°é›…â€æ–‡æ¡£è¯´æ˜](https://elegantrl.readthedocs.io/en/latest/helloworld/intro.html)
- [ElegantRL â€œå°é›…â€](https://github.com/AI4Finance-Foundation/ElegantRL/)

------------------------------------------------------------

## MARLåº“æ¨è

- [PKU-MARL/HARL: Official implementation of HARL algorithms based on PyTorch.](https://github.com/PKU-MARL/HARL)
- [PKU-MARL/Model-Based-MARL](https://github.com/PKU-MARL/Model-Based-MARL)
- [PKU-MARL/Multi-Agent-Transformer](https://github.com/PKU-MARL/Multi-Agent-Transformer)
- [zoeyuchao/mappo: This is the official implementation of Multi-Agent PPO.](https://github.com/zoeyuchao/mappo)
- [å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ åº”è¯¥å¦‚ä½•å­¦ä¹ ï¼ŸåŒ…æ‹¬æ¡†æ¶é€‰æ‹©ï¼Œä»£ç ä¿®æ”¹ç­‰ï¼Ÿ - çŸ¥ä¹](https://www.zhihu.com/question/599162746/answer/3139896142)

------------------------------------------------------------

## SLM Lab

- [SLM Lab - SLM Lab](https://slm-lab.gitbook.io/slm-lab/)
- [kengz/SLM-Lab: Modular Deep Reinforcement Learning framework in PyTorch. Companion library of the book "Foundations of Deep Reinforcement Learning".](https://github.com/kengz/SLM-Lab/)

------------------------------------------------------------

## Spinning Up in Deep RL

- [Welcome to Spinning Up in Deep RL! â€” Spinning Up documentation](https://spinningup.openai.com/en/latest/)
- [spinningup/readme.md at master Â· openai/spinningup](https://github.com/openai/spinningup/blob/master/readme.md)

------------------------------------------------------------

## Stable Baselines3

- [Stable Baselines3](https://github.com/DLR-RM/stable-baselines3/)
- [Stable-Baselines3 Docs - Reliable Reinforcement Learning Implementations â€” Stable Baselines3 1.7.0a5 documentation](https://stable-baselines3.readthedocs.io/en/master/)

------------------------------------------------------------

## å¤©æˆtianshou

- [thu-ml/tianshou: An elegant PyTorch deep reinforcement learning library.](https://github.com/thu-ml/tianshou/)
- [Get Started with Jupyter Notebook â€” Tianshou 0.4.10 documentation](https://tianshou.readthedocs.io/en/master/tutorials/get_started.html)

------------------------------------------------------------

## å¼ºåŒ–å­¦ä¹ åº“

- [udacity/deep-reinforcement-learning: Repo for the Deep Reinforcement Learning Nanodegree program](https://github.com/udacity/deep-reinforcement-learning)
- [google/dopamine: Dopamine is a research framework for fast prototyping of reinforcement learning algorithms.](https://github.com/google/dopamine)
- [tensorforce/tensorforce: Tensorforce: a TensorFlow library for applied reinforcement learning](https://github.com/tensorforce/tensorforce)
- [TF-Agents: A reliable, scalable and easy to use TensorFlow library for Contextual Bandits and Reinforcement Learning.](https://github.com/tensorflow/agents)

------------------------------------------------------------

## å¼ºåŒ–å­¦ä¹ ç¯å¢ƒ

- [Unity-Technologies/ml-agents: The Unity Machine Learning Agents Toolkit (ML-Agents) is an open-source project that enables games and simulations to serve as environments for training intelligent agents using deep reinforcement learning and imitation learning.](https://github.com/Unity-Technologies/ml-agents)
- [ä¸»é¡µ Â· andyljones/reinforcement-learning-discord-wiki Wiki](https://github.com/andyljones/reinforcement-learning-discord-wiki/wiki)

------------------------------------------------------------




# 0.å¼ºåŒ–å­¦ä¹ gymæ¡ˆä¾‹åˆé›†--ç®€å•è°ƒç”¨å³å¯

- [Farama-Foundation/Gymnasium: A standard API for single-agent reinforcement learning environments, with popular reference environments and related utilities (formerly Gym)](https://github.com/Farama-Foundation/Gymnasium)
- [Gymnasium Documentation](https://gymnasium.farama.org/)
- [RLcycle: A library for ready-made reinforcement learning agents and reusable components for neat prototyping](https://github.com/cyoon1729/RLcycle)


## æ™ºèƒ½ä½“ç®—æ³•

- [openai/multiagent-particle-envs: Code for a multi-agent particle environment used in the paper "Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments"](https://github.com/openai/multiagent-particle-envs)
- [Multi-Agent PPO (MAPPO).](https://github.com/marlbenchmark/on-policy)
- [multiagent-particle-envs: Code for a multi-agent particle environment used in the paper "Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments"](https://github.com/dingidng/multiagent-particle-envs)

------------------------------------------------------------

## å•æ™ºèƒ½ä½“ç®—æ³•

- [Rainbow:æ•´åˆDQNå…­ç§æ”¹è¿›çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼ - ç®€ä¹¦](https://www.jianshu.com/p/1dfd84cd2e69?utm_campaign=maleskine&utm_content=note&utm_medium=seo_notes&utm_source=recommendation)
- [æœ€å‰æ²¿ï¼šæ·±åº¦è§£è¯»Soft Actor-Critic ç®—æ³• - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/70360272)
- [SACè®ºæ–‡è§£è¯»ä»¥åŠç®€æ˜“ä»£ç å¤ç° - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/114236301)
- [æµ…è°ˆTD3ï¼šä»ç®—æ³•åŸç†åˆ°ä»£ç å®ç° - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/357719456)
- [ã€æ·±åº¦å¼ºåŒ–å­¦ä¹ ã€‘TD3ç®—æ³•ï¼šDDPGçš„è¿›åŒ–_chyçš„åšå®¢-CSDNåšå®¢](https://blog.csdn.net/weixin_45492196/article/details/107866309?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522162856566416780262541376%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=162856566416780262541376&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~baidu_landing_v2~default-6-107866309.first_rank_v2_pc_rank_v29&utm_term=TD3%E7%AE%97%E6%B3%95&spm=1018.2226.3001.4187)
- [TD3ï¼šåŒå»¶è¿Ÿæ·±åº¦ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦ç®—æ³•_å¸ƒè°·AIçš„ä¸“æ -CSDNåšå®¢_td3ç®—æ³•](https://blog.csdn.net/huibiannihao/article/details/106167522?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522162856566416780262541376%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=162856566416780262541376&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-3-106167522.first_rank_v2_pc_rank_v29&utm_term=TD3%E7%AE%97%E6%B3%95&spm=1018.2226.3001.4187)
- [Deep Reinforcement Learning - 1. DDPGåŸç†å’Œç®—æ³•_kenneth_yuçš„åšå®¢-CSDNåšå®¢_ddpg](https://blog.csdn.net/kenneth_yu/article/details/78478356)
- [Policy Gradientä¹‹A2Cç®—æ³• - é£æ¡¨AI Studio - äººå·¥æ™ºèƒ½å­¦ä¹ å®è®­ç¤¾åŒº](https://aistudio.baidu.com/aistudio/projectdetail/646481?channelType=0&channel=0)
- [æ·±åº¦å¼ºåŒ–å­¦ä¹  -- è¿›å‡»çš„ Actor-Criticï¼ˆA2C å’ŒA3Cï¼‰ - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/148492887?utm_source=wechat_session)
- [å¼ºåŒ–å­¦ä¹ ç®—æ³•TD3è®ºæ–‡çš„ç¿»è¯‘ä¸è§£è¯» - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/86297106?from_voters_page=true)
- [è®ºæ–‡ç¬”è®°ä¹‹SACæå‡ç®—æ³•_Tonçš„åšå®¢-CSDNåšå®¢_sacç®—æ³•](https://blog.csdn.net/MR_kdcon/article/details/118889768)
- [A2Cã€ppoï¼Œsac td3ç­‰](https://zhuanlan.zhihu.com/p/127792558)
- [A2Cã€ppoï¼Œsac td3ç­‰ ç®—æ³•é€‰æ‹©ç¯‡ - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/96010395)

------------------------------------------------------------

## å¤šæ™ºèƒ½ä½“ç®—æ³•

- [è¯¦ç»†ä»‹ç»äº†MADDPGç¯å¢ƒä¿¡æ¯ä»¥åŠæä¾›ç æº](https://www.cnblogs.com/lucifer1997/p/14864955.html)
- [ã€QMIXã€‘ä¸€ç§åŸºäºValue-Basedå¤šæ™ºèƒ½ä½“ç®—æ³• - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/353524210)
- [å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ å…¥é—¨ï¼ˆå››ï¼‰â€”â€”MADDPGç®—æ³• - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/53811876)
- [MADDPGåˆ†æåŠå…¶æ›´æ–°ç­–ç•¥è§è§£_æµå¹´å·²é€çš„åšå®¢-CSDNåšå®¢](https://blog.csdn.net/weixin_43145941/article/details/112726116)
- [å¤šæ™ºèƒ½ä½“æ·±åº¦å­¦ä¹ ç®—æ³•MADDPGçš„PARLå®è·µ - é£æ¡¨AI Studio - äººå·¥æ™ºèƒ½å­¦ä¹ å®è®­ç¤¾åŒº](https://aistudio.baidu.com/aistudio/projectdetail/643657?channelType=0&channel=0)
- [ä»ä»£ç åˆ°è®ºæ–‡ç†è§£å¹¶å¤ç°MADDPGç®—æ³•(PARL) - é£æ¡¨AI Studio - äººå·¥æ™ºèƒ½å­¦ä¹ å®è®­ç¤¾åŒº](https://aistudio.baidu.com/aistudio/projectdetail/637951?channelType=0&channel=0)

------------------------------------------------------------


# 5. RLé¡¹ç›®æ¡ˆä¾‹

- [DouZero: ä»é›¶å¼€å§‹é€šè¿‡è‡ªæˆ‘åšå¼ˆå¼ºåŒ–å­¦ä¹ æ¥å­¦æ‰“æ–—åœ°ä¸»](https://github.com/kwai/DouZero/blob/main/README.zh-CN.md)
- [deepmind/open_spiel: OpenSpiel is a collection of environments and algorithms for research in general reinforcement learning and search/planning in games.](https://github.com/deepmind/open_spiel/)
- [datamllab/rlcardï¼šçº¸ç‰Œï¼ˆæ‰‘å…‹ï¼‰æ¸¸æˆä¸­çš„å¼ºåŒ–å­¦ä¹ /AI æœºå™¨äºº - Blackjackã€Leducã€Texasã€DouDizhuã€Mahjongã€UNOã€‚](https://github.com/datamllab/rlcard/)
- [couponç²¾å‡†è¥é”€](https://mp.weixin.qq.com/s/wgVR-JltgrzNa6xVZ-jNsA)
- [DataFunTalkå¼ºåŒ–å­¦ä¹ åœ¨è°ƒåº¦ä»»åŠ¡æµé‡ç›‘æ§åº”ç”¨](https://www.zhihu.com/question/277325426/answer/2656572790)

------------------------------------------------------------

## AIç©ç‹è€…è£è€€

- [è…¾è®¯å¼ºåŒ–å­¦ä¹ å¼€æºç‹è€…è£è€€](https://github.com/tencent-ailab/hok_env)
- [FengQuanLi/ResnetGPT: ç”¨Resnet101+GPTæ­å»ºä¸€ä¸ªç©ç‹è€…è£è€€çš„AI](https://github.com/FengQuanLi/ResnetGPT)
- [FengQuanLi/WZCQ: ç”¨åŸºäºç­–ç•¥æ¢¯åº¦å¾—å¼ºåŒ–å­¦ä¹ æ–¹æ³•è®­ç»ƒAIç©ç‹è€…è£è€€](https://github.com/FengQuanLi/WZCQ)

------------------------------------------------------------

## åŸºäºDDPGç®—æ³•çš„è‚¡ç¥¨é‡åŒ–äº¤æ˜“

- [åŸºäºDDPGç®—æ³•çš„è‚¡ç¥¨é‡åŒ–äº¤æ˜“ - é£æ¡¨AI Studio](https://aistudio.baidu.com/aistudio/projectdetail/2221634)
- [æ•°æ®é›†ï¼šåŸºäºDDPGç®—æ³•çš„è‚¡ç¥¨é‡åŒ–äº¤æ˜“](https://aistudio.baidu.com/aistudio/datasetdetail/102715)
- [ä½¿ç”¨DDPGç®—æ³•åº”ç”¨äºè‚¡ç¥¨äº¤æ˜“](https://github.com/PaddlePaddle/awesome-DeepLearning/blob/master/examples/DDPG%20for%20Stock%20Trading/README.md)

------------------------------------------------------------

## å¼ºåŒ–å­¦ä¹ ä¸‹äº”å­æ£‹

- [dowdyboy/lin_xiao_five_in_a_row: â€œä¸´éœ„â€æ·±åº¦å¼ºåŒ–å­¦ä¹ äº”å­æ£‹](https://github.com/dowdyboy/lin_xiao_five_in_a_row)

------------------------------------------------------------

## å¼ºåŒ–å­¦ä¹ æ‰“æ‰‘å…‹

- [RLcard Showdownæ–—åœ°ä¸»demoå±•ç¤º](https://douzero.org/)
- [kwai/DouZero: [ICML 2021] DouZero: Mastering DouDizhu with Self-Play Deep Reinforcement Learning | æ–—åœ°ä¸»AI](https://github.com/kwai/DouZero)
- [datamllab/rlcard: Reinforcement Learning / AI Bots in Card (Poker) Games - Blackjack, Leduc, Texas, DouDizhu, Mahjong, UNO.](https://github.com/datamllab/rlcard)
- [[2106.06135] DouZero: Mastering DouDizhu with Self-Play Deep Reinforcement Learning](https://arxiv.org/abs/2106.06135)

------------------------------------------------------------

## é‡åŒ–äº¤æ˜“

- [AI4Finance Foundation](https://github.com/AI4Finance-Foundation)
- [AI4Finance-Foundation/FinGPT: Data-Centric FinGPT. Open-source for open finance! Revolutionize ğŸ”¥ We release the trained model on HuggingFace.](https://github.com/AI4Finance-Foundation/FinGPT)
- [AI4Finance-Foundation/RLSolver: Solvers for NP-hard and NP-complete problems with an emphasis on high-performance GPU computing.](https://github.com/AI4Finance-Foundation/RLSolver)
- [AI4Finance-Foundation/FinRL-Meta: FinRLÂ­-Meta: Dynamic datasets and market environments for FinRL.](https://github.com/AI4Finance-Foundation/FinRL-Meta/tree/master)
- [AI4Finance-Foundation/FinRL-Tradingï¼šç”¨äºäº¤æ˜“ã€‚ è¯·åŠ æ˜Ÿæ ‡ã€‚](https://github.com/AI4Finance-Foundation/FinRL-Trading)
- [AI4Finance-Foundation/FinRL: FinRL: Financial Reinforcement Learning. ğŸ”¥](https://github.com/AI4Finance-Foundation/FinRL)
- [åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„é‡‘èäº¤æ˜“ç­–ç•¥ï¼ˆFinRL+Stable baselines3ï¼Œä»¥é“ç¼æ–¯30è‚¡ç¥¨ä¸ºä¾‹ï¼‰ - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/563238735)
- [é‡åŒ–æŠ•èµ„çš„å¼ºåŒ–å­¦ä¹ ç¥å™¨ï¼FinRL å…¥é—¨æŒ‡å— - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/538026404)
- [å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learningï¼‰åœ¨é‡åŒ–äº¤æ˜“é¢†åŸŸå¦‚ä½•åº”ç”¨ï¼Ÿ - çŸ¥ä¹](https://www.zhihu.com/question/45116323/answer/2933125710)
- [ã€FinRLã€‘é‡åŒ–äº¤æ˜“æ·±åº¦å¼ºåŒ–å­¦ä¹ åº“-ä½¿ç”¨ 1 - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/409775057)

------------------------------------------------------------


# 5.çŸ¥ä¹-æ–‡ç« 

- [è…¾è®¯å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ å¤§èµ›å† å†›æ€è·¯åˆ†äº« - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/654972230)
- [å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ -PYMARLåŒæ–¹å¯¹æˆ˜ç®—æ³•æ¡†æ¶ - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/597351796)
- [IJCAI2023 å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ è®ºæ–‡åˆé›† - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/635124693)
- [å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ èµ„æºåˆ†äº«(GitHubæŒç»­æ›´æ–°) - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/372550158)

**[â¬† è¿”å›READMEç›®å½•](../README.md#ç›®å½•)**
**[â¬† Back to Contents](../README-EN.md#contents)**