# LLM合集-语言

LLM合集-语言模块构建了涵盖50+个主流语言大模型的完整技术生态图谱，为AI开发者提供全方位的语言模型选型和应用指南。该模块系统性地整理了OpenAI GPT系列、Anthropic Claude系列、Google Gemini/PaLM系列、Meta LLaMA系列等国际顶级模型，以及阿里通义千问、百度文心一言、腾讯混元、字节豆包、智谱ChatGLM、月之暗面Kimi、零一万物Yi、面壁智能CPM、清华ChatGLM等国产优秀模型。技术特色涵盖了从7B到175B+参数规模的多样化模型架构，详细解析了Transformer、Mamba、Mixture of Experts等前沿技术路线，以及指令微调、人类反馈强化学习、思维链推理等核心训练技术。

模块深入介绍了各模型在文本生成、代码编写、数学推理、多语言理解、长文本处理等核心能力维度的表现特点，以及API调用、本地部署、模型微调、推理优化等工程化实践方案。内容还包括开源模型生态（Hugging Face、ModelScope、OpenBMB）、商业模型服务（OpenAI API、Claude API、文心千帆）、模型评测基准、性能对比分析等实用信息，以及最新模型发布、技术突破、应用案例等前沿动态，帮助开发者在丰富的语言模型生态中找到最适合的技术方案，构建高质量的自然语言处理应用。

- [机器之心SOTA！模型](https://sota.jiqizhixin.com/)

- [0.中国大模型列表 Awesome LLMs --241个](https://github.com/wgwang/awesome-LLMs-In-China)
- [中国大模型合集133个](https://github.com/wgwang/LLMs-In-China)
- [大语言模型集合/awesome-pretrained-chinese-nlp-models: Awesome Pretrained Chinese NLP Models，高质量中文预训练模型&大模型&多模态模型&大语言模型集合](https://github.com/lonePatient/awesome-pretrained-chinese-nlp-models)

# 📋  目录

1. 1.LLM合集-语言.md
2. 0.大模型合集
3. [DeepSeek](#1deepseek杭州深度求索)
4. 1.anthropic
5. 1.字节扣子coze
6. 1.谷歌gemini
7. 1.豆包
8. 1.通义千问Qwen
9. 12.360智脑
10. 12.硅基流动siliconflow-14元
11. 13.Blue LM蓝心大模型
12. 13.阶跃星辰
13. 15.序列猴子
14. 2.Grok
15. 2.Mistral AI
16. 2.minimaxi
17. 2.minimaxi/M1
18. 2.文心千帆
19. 2.智谱清言ChatGLM
20. 2.智谱清言ChatGLM/AutoGLM
21. 2.腾讯混元大模型
22. 2.腾讯混元大模型/工业级3D
23. 2.腾讯混元大模型/生3D
24. 2.腾讯混元大模型/生图
25. 2.腾讯混元大模型/生文
26. 2.腾讯混元大模型/生视频
27. 20.紫东太初
28. 21.智源AI-悟道
29. 3.书生浦源
30. 3.书生浦源/VL多模态模型
31. 3.书生浦源/chat模型
31. 3.天工Skywork
32. 4.月之暗面moonshot
33. 4.月之暗面moonshot/kimi-dev
34. 8.科大讯飞
35. 9.Llama-meta
36. 9.YI零一万物
37. 9.小红书/dots.llm1
38. 9.百川大模型
39. 9.面壁智能miniCPM

# 1.豆包

- [豆包大模型团队 - 字节跳动大模型团队](https://team.doubao.com/zh/)
- [豆包官网](https://www.doubao.com/product)
- [豆包 - 字节跳动旗下 AI 智能助手](https://www.doubao.com/chat/?channel=bing_sem&source=dbweb_bing_sem_xhs_cpc_pp_tup_hexin_web_05&keywordid=77309832906381&msclkid=2fead44ea24e1af89035bc4f142eeda9)

# 1.谷歌gemini

- [Gemma open models  |  Google AI for Developers](https://ai.google.dev/)

## gpt-oss – OpenAI开源的推理模型系列

GPT-OSS是由OpenAI推出的首个开源大语言模型系列，包含gpt-oss-120b和gpt-oss-20b两个版本。这些模型采用开放权重（open-weight）形式，并遵循Apache 2.0许可协议发布，旨在以低成本提供高性能和强大的推理能力，支持本地部署和自定义微调。其发布代表了OpenAI在开源模型领域迈出的重要一步，以促进AI研究、创新和更透明的AI发展。

![chart.png](https://free.picui.cn/free/2025/08/06/6892c73d1cdaa.png)

![chart (1).png](https://free.picui.cn/free/2025/08/06/6892c7337a0fd.png)

#### 核心功能
GPT-OSS模型具备卓越的推理能力、工具使用能力和指令遵循能力。它们采用思维链（Chain-of-Thought, CoT）推理方法，能够分步骤解答复杂问题，并支持浏览网页、调用云端模型、执行代码以及作为AI代理进行软件导航等高级功能。这些模型是文本专用型，但针对消费级硬件进行了优化，以实现高效部署和低延迟推理。

#### 技术原理
GPT-OSS模型是基于GPT-2和GPT-3架构的自回归MoE（Mixture-of-Experts）Transformer模型。gpt-oss-120b包含36层（116.8B总参数），gpt-oss-20b包含24层（20.9B总参数）。模型在每个注意力块和MoE块之前应用均方根归一化（RMS Norm），并采用Pre-LN（Layer Normalization）放置。训练结合了强化学习和OpenAI内部先进技术，并进行了全面的安全训练，包括预训练阶段的有害数据过滤（如CBRN相关），以及通过审慎对齐和指令层级机制来拒绝不安全提示和防御提示注入。

#### 应用场景
GPT-OSS模型适用于加速前沿AI研究、促进AI技术创新以及实现更安全透明的AI开发。由于其支持本地部署和在消费级硬件上运行，开发者和企业可以获得对延迟、成本和隐私的完全控制。这使得GPT-OSS非常适合需要高性能推理、精细化控制和私有化部署的各类场景，例如：开发定制化AI应用、模型微调、教育研究、探索AI代理能力以及需要避免API限制的场景。

gpt-oss的项目地址
*  项目官网：https://openai.com/zh-Hans-CN/index/introducing-gpt-oss/
*  GitHub仓库：https://github.com/openai/gpt-oss
*  HuggingFace模型库：https://huggingface.co/collections/openai/gpt-oss-68911959590a1634ba11c7a4
*  在线体验Demo：https://gpt-oss.com/

# 1.通义千问Qwen

- [如何获取通义千问API的KEY_模型服务灵积(DashScope)-阿里云帮助中心](https://help.aliyun.com/zh/dashscope/developer-reference/acquisition-and-configuration-of-api-key?spm=a2c4g.2399481.0.0)
- [QwenLM/Qwen3: Qwen3 is the large language model series developed by Qwen team, Alibaba Cloud.](https://github.com/QwenLM/Qwen3
- [Qwen](https://qwen.readthedocs.io/zh-cn/latest/index.html)
- [QwenLM/Qwen2.5-VL: Qwen2.5-VL is the multimodal large language model series developed by Qwen team, Alibaba Cloud.](https://github.com/QwenLM/Qwen2.5-VL)
- [QwenLM/Qwen2.5-Omni: Qwen2.5-Omni is an end-to-end multimodal model by Qwen team at Alibaba Cloud, capable of understanding text, audio, vision, video, and performing real-time speech generation.](https://github.com/QwenLM/Qwen2.5-Omni)
- [QwenLM/Qwen2.5-Coder: Qwen2.5-Coder is the code version of Qwen2.5, the large language model series developed by Qwen team, Alibaba Cloud.](https://github.com/QwenLM/Qwen2.5-Coder)


# 1.字节扣子coze

- [扣子 - 文档中心](https://www.coze.cn/docs/guides/prebuilt_bot)
- [扣子空间](https://www.coze.cn/space-preview)
- [Bot 商店 - 扣子](https://www.coze.cn/store/bot?cate_type=publish_mode&cate_value=1)
- [豆包大模型-火山引擎](https://www.volcengine.com/product/doubao?utm_source=ai-bot.cn)

## Seed-OSS – 字节开源大模型

Seed-OSS 是由字节跳动 Seed 团队开发的一系列开源大型语言模型。该模型系列旨在提供强大的长上下文处理、推理、智能体和通用能力，并具备友好的开发者特性。尽管仅使用 12T tokens 进行训练，Seed-OSS 在多项流行公开基准测试中展现出卓越性能，并以 Apache-2.0 许可证向开源社区发布，主要针对国际化（i18n）用例进行了优化。

[![seed-oss.png](https://i.postimg.cc/50SY3TfT/seed-oss.png)](https://postimg.cc/ZB05YfBx)

#### 核心功能
*   **原生长上下文支持：** 模型能够处理高达 512K 的长上下文输入，显著提升对长文本的理解和生成能力。
*   **增强推理能力：** 经过专门优化，在推理任务中表现出色，同时保持了均衡且卓越的通用能力。
*   **智能体能力：** 在工具使用和问题解决等智能体任务中表现非凡。
*   **灵活的思维预算控制：** 允许用户根据需求动态调整推理长度，从而提高实际应用场景中的推理效率。
*   **研究友好性：** 发布了包含和不包含指令数据的预训练模型，为研究社区提供更多样化的选择。

#### 技术原理
Seed-OSS 采用流行的因果语言模型架构，并集成了多项先进技术以优化性能和效率：
*   **RoPE (Rotary Position Embeddings)：** 用于处理序列中的位置信息，增强模型对长距离依赖的理解。
*   **GQA (Grouped-Query Attention)：** 一种注意力机制优化，旨在减少内存占用和提高推理速度。
*   **RMSNorm (Root Mean Square Normalization)：** 一种归一化技术，有助于稳定训练过程。
*   **SwiGLU 激活函数：** 提供更好的非线性转换能力，提升模型表达力。

#### 应用场景
*   **长文本内容处理：** 适用于需要理解和生成超长文本的应用，例如文档摘要、长篇写作辅助等。
*   **复杂问题推理：** 可应用于需要多步逻辑推理的场景，如智能问答、知识图谱构建与查询等。
*   **智能体开发：** 作为底层模型，支持开发具备工具调用、自主规划和问题解决能力的AI智能体。
*   **国际化多语言应用：** 针对国际用例进行优化，可服务于跨语言交流、多语言内容创作等全球化场景。
*   **前沿AI研究：** 为学术界和研究机构提供高质量的开源模型，促进在长上下文、推理和Agent领域的研究与探索。


* GitHub仓库：https://github.com/ByteDance-Seed/seed-oss
* HuggingFace模型库：https://huggingface.co/collections/ByteDance-Seed/seed-oss-68a609f4201e788db05b5dcd


# 1.anthropic

- [Anthropic](https://www.anthropic.com/)

# 1.DeepSeek：杭州深度求索

- [DeepSeek | 深度求索](https://www.deepseek.com/)
- [DeepSeek API Docs官方文档](https://api-docs.deepseek.com/zh-cn/updates/)
- [DeepSeek](https://platform.deepseek.com/sign_in)
- [deepseek-ai/DeepSeek-R1](https://github.com/deepseek-ai/DeepSeek-R1)
- [deepseek-ai/DeepSeek-V3](https://github.com/deepseek-ai/DeepSeek-V3)
- [deepseek-ai/awesome-deepseek-integration: Integrate the DeepSeek API into popular softwares](https://github.com/deepseek-ai/awesome-deepseek-integration)
- [deepseek-ai/DeepSeek-Coder: DeepSeek Coder: Let the Code Write Itself](https://github.com/deepseek-ai/DeepSeek-Coder)

# 2.腾讯混元大模型

- [腾讯混元](https://hunyuan.tencent.com/)
- [腾讯混元大模型_大语言模型_自然语言大模型- 腾讯云](https://cloud.tencent.com/product/hunyuan)
- [角色 - 访问管理 - 控制台](https://console.cloud.tencent.com/cam/role)

## 生成3D模型

- [腾讯混元3D](https://3d-models.hunyuan.tencent.com/)
- [Hunyuan3D-2/assets/report/Tencent_Hunyuan3D_2_0.pdf at main · Tencent/Hunyuan3D-2](https://github.com/Tencent/Hunyuan3D-2/blob/main/assets/report/Tencent_Hunyuan3D_2_0.pdf)
- [tencent/Hunyuan3D-2 · Hugging Face](https://huggingface.co/tencent/Hunyuan3D-2)
- [Tencent/Hunyuan3D-2: High-Resolution 3D Assets Generation with Large Scale Hunyuan3D Diffusion Models.](https://github.com/Tencent/Hunyuan3D-2)

## 生成视频

- [腾讯混元文生视频](https://aivideo.hunyuan.tencent.com/)
- [Tencent/HunyuanVideo: HunyuanVideo: A Systematic Framework For Large Video Generation Model](https://github.com/Tencent/HunyuanVideo)
- [tencent/HunyuanVideo · Hugging Face](https://huggingface.co/tencent/HunyuanVideo)
- [hunyuanvideo.pdf](https://aivideo.hunyuan.tencent.com/hunyuanvideo.pdf)

## 生成图像

- [腾讯混元DiT](https://dit.hunyuan.tencent.com/)
- [Tencent/HunyuanDiT: Hunyuan-DiT : A Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding](https://github.com/Tencent/HunyuanDiT)
- [Tencent-Hunyuan/HunyuanDiT · Hugging Face](https://huggingface.co/Tencent-Hunyuan/HunyuanDiT)

## 生文

- [腾讯混元](https://llm.hunyuan.tencent.com/#/)
- [Hunyuan Large - a Hugging Face Space by tencent](https://huggingface.co/spaces/tencent/Hunyuan-Large)
- [Tencent/Tencent-Hunyuan-Large](https://github.com/Tencent/Tencent-Hunyuan-Large)

# 2.文心千帆
- [PaddlePaddle/ERNIE](https://github.com/PaddlePaddle/ERNIE)
- [文心千帆大模型](https://cloud.baidu.com/product/wenxinworkshop)
- [ERNIE-Bot - 千帆大模型平台 | 百度智能云文档](https://cloud.baidu.com/doc/WENXINWORKSHOP/s/jlil56u11)
- [千帆大模型：平台快速开始](https://cloud.baidu.com/doc/WENXINWORKSHOP/s/qlgujhcpo)


# 2.智谱清言ChatGLM

- [智谱清言](https://chatglm.cn/main/alltoolsdetail)
- [智谱AI开放平台](https://open.bigmodel.cn/)
- [ChatGLM版本介绍](https://chatglm.cn/blog)
- [1. 智谱·AI 开源模型列表 - 飞书云文档](https://zhipu-ai.feishu.cn/wiki/YInmwPmyii67VRkzU3BchPNzncg)
- [GLM4 API 开源教程](https://github.com/MetaGLM/glm-cookbook/)
- [GLM-4-github](https://github.com/THUDM/GLM-4)
- [THUDM/GLM-4-Voice: GLM-4-Voice | 端到端中英语音对话模型](https://github.com/THUDM/GLM-4-Voice)
- [THUDM/CogView4: CogView4, CogView3-Plus and CogView3(ECCV 2024)](https://github.com/THUDM/CogView4)
- [THUDM/AgentTuning: AgentTuning: Enabling Generalized Agent Abilities for LLMs](https://github.com/THUDM/AgentTuning)

## AutoGLM

- [AutoGLM - 您的专属智能AI助手](https://agent.aminer.cn/)
- [智谱清言插件 - 你的浏览器AI助手](https://new-front.chatglm.cn/webagent/landing/index.html?channel=autoglm_android)
- [AutoGLM 沉思](https://autoglm-research.zhipuai.cn/?channel=autoglm_android)

## GLM-4.5 –SOTA 模型

#### 简介
GLM-4.5是智谱AI（Z.ai）推出的一款新一代旗舰级开源大模型，旨在原生融合推理、代码和智能体（Agent）能力，是业界首款专注于智能体应用的SOTA模型。它在多个评测基准中表现卓越，综合性能达到开源模型的顶尖水平，尤其在代码智能体场景中表现优异。



![智谱.png](https://free.picui.cn/free/2025/07/29/6888b2c5ed9de.png)

#### 核心功能
*   **推理能力：** 提供强大的逻辑推理能力，能够处理复杂任务并进行深度思考。
*   **代码生成与理解：** 具备出色的代码智能，支持代码的生成、理解、调试和优化。
*   **智能体能力：** 专为构建和驱动智能体设计，能够作为核心驱动力，实现自主规划与执行。
*   **多版本支持：** 包含GLM-4.5（3550亿参数）和GLM-4.5-Air（1060亿参数）等版本，兼顾性能与效率。
*   **混合推理模式：** 支持“思考模式”和“非思考模式”，以适应复杂任务与即时响应的不同需求。

#### 技术原理
GLM-4.5采用先进的混合专家（MoE）架构，通过激活部分专家模型来高效处理任务。例如，GLM-4.5拥有3550亿总参数和320亿激活参数，而GLM-4.5-Air则更为紧凑，拥有1060亿总参数和120亿激活参数。模型在参数效率上实现了显著优化，在保持高性能的同时，参数量远低于同级别模型。其技术栈支持深度思考（Deep Thinking）、流式输出（Streaming Output）、函数调用（Function Call）、上下文缓存（Context Caching）和结构化输出（Structured Output）等高级功能，提升了模型的实用性和集成能力。

#### 应用场景
*   **AI智能体开发：** 作为核心驱动引擎，用于构建具备自主决策、规划和执行能力的各种智能体应用。
*   **自动化编程与开发辅助：** 辅助开发者进行代码生成、错误排查、代码重构等，提高开发效率。
*   **复杂问题推理：** 在金融分析、科学研究、医疗诊断等需要复杂逻辑推理的领域提供智能支持。
*   **企业级AI解决方案：** 适用于需要高性能、高效率和高可靠性AI模型的企业级应用场景。
*   **对话系统与智能助手：** 提升对话机器人、虚拟助手在理解、响应和执行复杂指令方面的能力。


* GitHub仓库：https://github.com/zai-org/GLM-4.5
* HuggingFace仓库： https://huggingface.co/collections/zai-org/glm-45-687c621d34bda8c9e4bf503b
* ModelScope仓库：https://modelscope.cn/collections/GLM-45-b8693e2a08984f
体验地址：
* HuggingFace： https://huggingface.co/spaces/zai-org/GLM-4.5-Space
* ModelScope：https://modelscope.cn/studios/ZhipuAI/GLM-4.5-Demo

# 2.Grok

- [Grok / X](https://x.com/i/grok)
- [xai-org/grok-1: Grok open release](https://github.com/xai-org/grok-1)

# 2.Mistral AI
- [Agents - La Plateforme - Mistral AI](https://console.mistral.ai/build/agents)
- [Le Chat - Mistral AI](https://chat.mistral.ai/chat)
- [mistralai/mistral-inference: Official inference library for Mistral models](https://github.com/mistralai/mistral-inference)

# 3.书生浦源

- [InternLM/InternLM: Official release of InternLM series (InternLM, InternLM2, InternLM2.5, InternLM3).](https://github.com/InternLM/InternLM)
- [书生·浦语](https://internlm.intern-ai.org.cn/)
- [书生·浦语-开发者社区](https://internlm.intern-ai.org.cn/developers/community)
- [OpenXLab浦源](https://openxlab.org.cn/home)
- [OpenXLab浦源 - 开放项目](https://openxlab.org.cn/openplatform?lang=zh-CN)
- [书生浦源实战模型中心-OpenXLab](https://openxlab.org.cn/models/InternLM/subject)
- [首页_上海人工智能实验室](https://www.shlab.org.cn/)




## chat模型

- [InternLM/InternLM: Official release of InternLM2.5 7B base and chat models. 1M context support](https://github.com/InternLM/InternLM/tree/main)
- [InternLM/README_zh-CN.md at main · InternLM/InternLM](https://github.com/InternLM/InternLM/blob/main/README_zh-CN.md)

## VL多模态模型

- [OpenGVLab/InternVL: [CVPR 2024 Oral] InternVL Family: A Pioneering Open-Source Alternative to GPT-4V. 接近GPT-4V表现的可商用开源多模态对话模型](https://github.com/OpenGVLab/InternVL)
- [InternVL2-8B · 模型库](https://modelscope.cn/models/OpenGVLab/InternVL2-8B)
- [InternVL/README_zh.md at main · OpenGVLab/InternVL](https://github.com/OpenGVLab/InternVL/blob/main/README_zh.md)

# 3.Skywork天工

[Skywork天工-R1V]https://github.com/SkyworkAI/Skywork-R1V

[Skywork天工-SkyReels-V2]https://github.com/SkyworkAI/SkyReels-V2

[Skywork天工-SkyReels-V1]https://github.com/SkyworkAI/SkyReels-V1

## Skywork MindLink – 昆仑万维开源的推理大模型

#### 简介
MindLink是由昆仑万维（Kunlun Inc.）SkyworkAI团队开发的一系列大型语言模型。这些模型基于Qwen架构，并融合了最新的后训练技术，旨在提供在多种AI场景中表现卓越的通用能力。MindLink系列模型目前包含32B和72B等不同参数规模的版本，支持长达128K的上下文长度。

#### 核心功能
*   **多领域通用性能：** 在各类常见基准测试中展现出强大的性能，适用于广泛的AI应用场景。
*   **长上下文处理能力：** 支持128K的超长上下文窗口，能够处理和理解大量的输入信息。
*   **API访问：** 提供API接口供开发者进行模型探索和测试，便于集成到各类应用中。
*   **持续优化与迭代：** 团队致力于模型的持续优化和改进，欢迎用户反馈以推动模型演进。

#### 技术原理
MindLink模型基于Qwen架构进行开发，并在此基础上集成了SkyworkAI团队在后训练（Post-training）方面的最新进展。这意味着模型在基础预训练之后，通过特定的微调、指令跟随或强化学习等技术进一步提升了其性能和泛化能力。其支持的128K上下文长度表明模型采用了高效的注意力机制或位置编码技术，使其能够处理远超传统模型的长序列输入，从而更好地理解复杂语境和长文本信息。模型在Hugging Face上提供不同量化版本的下载，暗示其在部署和效率方面也进行了优化，以适应不同的硬件环境。

#### 应用场景
*   **通用AI任务处理：** 适用于多种AI场景，包括但不限于内容生成、智能问答、文本摘要、翻译等。
*   **学术研究与开发：** 作为基础模型，可供研究人员进行二次开发、模型微调以及新算法的验证。
*   **企业级应用集成：** 通过提供的API接口，企业可将其集成到智能客服、自动化办公、数据分析等内部系统中。
*   **长文本理解与生成：** 凭借其超长上下文能力，特别适用于需要深入理解长篇文档或生成长篇内容的场景，例如报告撰写、法律文书分析、代码生成等。


Skywork MindLink的项目地址
* Github仓库：https://github.com/SkyworkAI/MindLink
* 技术论文：https://github.com/SkyworkAI/MindLink/blob/main/mindlink.pdf
* HuggingFace模型库：
  * MindLink-32B：https://huggingface.co/Skywork/MindLink-32B-0801
  * MindLink-72B：https://huggingface.co/Skywork/MindLink-72B-0801

# 3.月之暗面moonshot

- [Moonshot AI - 开放平台](https://platform.moonshot.cn/console/api-keys)
- [Moonshot AI 开放平台](https://platform.moonshot.cn/docs/intro#%E4%B8%BB%E8%A6%81%E6%A6%82%E5%BF%B5)
- [Kimi.ai - 会推理解析，能深度思考的AI助手](https://kimi.moonshot.cn/)

# 3.科大讯飞

- [讯飞星火大模型-AI大语言模型-星火大模型-科大讯飞](https://xinghuo.xfyun.cn/sparkapi)
- [讯飞AI社区](https://developer.xfyun.cn/thread/116465)

# 3.百川大模型

- [百川大模型-汇聚世界知识 创作妙笔生花-百川智能](https://platform.baichuan-ai.com/docs/api)

# 3.面壁智能miniCPM

- [OpenBMB - 让大模型飞入千家万户](https://www.openbmb.cn/home)
- [OpenBMB](https://github.com/OpenBMB)
- [OpenBMB/MiniCPM: MiniCPM3-4B: An edge-side LLM that surpasses GPT-3.5-Turbo.](https://github.com/OpenBMB/MiniCPM)
- [OpenBMB/VisCPM: [ICLR'24 spotlight] Chinese and English Multimodal Large Model Series (Chat and Paint) | 基于CPM基础模型的中英双语多模态大模型系列](https://github.com/OpenBMB/VisCPM)
- [MiniCPM-V: MiniCPM-V 2.6: A GPT-4V Level MLLM for Single Image, Multi Image and Video on Your Phone](https://github.com/OpenBMB/MiniCPM-V)

# 3小红书dots.llm1

- [rednote-hilab (rednote-hilab)](https://huggingface.co/rednote-hilab)
- [rednote-hilab/dots.llm1](https://github.com/rednote-hilab/dots.llm1)

# 3.Llama-meta

- [llama中文模型开源社区](https://llama.family/model)
- [Llama 中文社区](https://llama.family/chat/?ref=openi.cn#/)
- [meta-llama/llama3: The official Meta Llama 3 GitHub site](https://github.com/meta-llama/llama3)
- [meta-llama/llama-recipes: Scripts for fine-tuning Meta Llama3 with composable FSDP & PEFT methods to cover single/multi-node GPUs. Supports default & custom datasets for applications such as summarization and Q&A. Supporting a number of candid inference solutions such as HF TGI, VLLM for local or cloud deployment. Demo apps to showcase Meta Llama3 for WhatsApp & Messenger.](https://github.com/meta-llama/llama-recipes)
- [meta-llama/llama: Inference code for Llama models](https://github.com/meta-llama/llama)

# 3.minimaxi

- [MiniMax-与用户共创智能](https://platform.minimaxi.com/)
- [MiniMax Agent - Your AI Supercompanion, Think Faster, Achieve More](https://agent.minimax.io/)

# 3.YI零一万物

- [零一万物大模型开放平台](https://platform.lingyiwanwu.com/apikeys)

# 3.360智脑

- [360智脑 — 以人为本，安全可信](https://ai.360.com/open)

# 3.硅基流动siliconflow

- [SiliconCloud](https://cloud.siliconflow.cn/fine-tune)

# 3.阶跃星辰

- [阶跃星辰开放平台](https://platform.stepfun.com/)

# 3.Blue LM蓝心大模型

- [vivo-ai-lab/BlueLM: BlueLM(蓝心大模型): Open large language models developed by vivo AI Lab](https://github.com/vivo-ai-lab/BlueLM)
- [蓝心大模型 - vivo开发者社区](https://developers.vivo.com/product/ai/bluelm?ref=openi.cn)

# 3.序列猴子

- [序列猴子开放平台](https://openapi.mobvoi.com/llm)

# 3.紫东太初

- [紫东太初大模型开放平台](https://ai-maas.wair.ac.cn/?ref=openi.cn)
- [紫东太初](https://taichu-web.ia.ac.cn/?ref=openi.cn)


# 3.智源AI-悟道

- [基础模型研究中心-智源“悟道”人工智能大模型-智源研究院官网](https://www.baai.ac.cn/portal/article/index/cid/49/id/518.html?ref=openi.cn)


##  XBai o4  大模型

XBai o4 是由 MetaStone AI（问小白）开发并开源的第四代大语言模型，专注于提升复杂推理能力。该模型已在GitHub和Hugging Face上发布，旨在促进AI技术的透明度和协作。XBai o4在复杂推理任务中表现出色，其性能在某些基准测试中甚至超越了OpenAI-o3-mini和Anthropic的Claude Opus，是开源AI领域的重要进展。

![image.png](https://i.postimg.cc/hjnKr198/image.png)

#### 核心功能
XBai o4 的核心功能在于其强大的深度推理能力和高质量推理轨迹选择。它能够同时实现深入的逻辑推理和选择最优的推理路径，从而提供更快且更高质量的响应。通过优化推理成本，特别是在策略奖励模型（PRMs）上的显著降低，XBai o4展现了卓越的效率。

#### 技术原理
XBai o4 基于其独创的“反思性生成形式”（reflective generative form）进行训练，该形式将“长链思维强化学习”（Long-CoT Reinforcement Learning）与“过程奖励学习”（Process Reward Learning）融合到一个统一的训练框架中。此外，通过在PRMs和策略模型之间共享骨干网络，该模型显著降低了PRMs的推理成本，提升了推理效率和质量。

#### 应用场景
XBai o4 作为一款高性能的开源推理模型，预计将在多个领域发挥重要作用。其主要应用场景包括：
*   **教育与研究**：为学术研究和教育领域的复杂问题提供强大的推理支持。
*   **企业应用**：在需要高级决策和问题解决能力的商业场景中，如智能客服、数据分析、自动化决策系统等。
*   **AI技术开发**：作为开源基础模型，促进全球AI生态系统的创新与发展，降低AI技术应用的门槛。



* GitHub仓库：https://github.com/MetaStone-AI/XBai-o4/
* HuggingFace模型库：https://hf-mirror.com/MetaStoneTec/XBai-o4


## 美团 LongCat-Flash-Chat

美团正式发布并开源 LongCat - Flash - Chat。该模型采用创新性混合专家模型架构，实现计算效率与性能双重优化，推理速度快，适合复杂智能体应用。在多领域基准测试中表现优异，还提供两种高效部署方案，已在 Github、Hugging Face 平台开源。

#### 核心功能
- 计算效率与性能优化：创新性架构使计算效率和性能双提升，少量激活参数时性能比肩主流模型。
- 快速推理：推理速度快，适合耗时较长的复杂智能体应用。
- 多领域表现良好：在通用领域知识、智能体工具使用、编程、指令遵循等方面表现出色。
- 高效部署：提供基于 SGLang 和 vLLM 的两种高效部署方案。

#### 技术原理
- 架构层面：采用混合专家模型（Mixture - of - Experts, MoE）架构，引入“零计算专家（Zero - Computation Experts） ”机制，实现算力按需分配和高效利用。
- 训练优化：训练过程采用 PID 控制器实时微调专家偏置，稳定单 token 平均激活量；层间铺设跨层通道，使通信和计算并行；对常用大模型组件和训练方式改进，使用超参迁移和模型层叠加方式训练。
- 底层优化：定制化底层优化，实现高效训练和高推理速度。

#### 应用场景
- 复杂智能体应用：因其推理速度快，适合耗时较长的复杂智能体任务。
- 通用知识问答：在通用领域知识基准测试表现好，可用于知识问答场景。
- 编程辅助：在编程相关基准测试有竞争力，可辅助编程工作。
- 指令遵循任务：在指令遵循方面优势显著，适用于需遵循复杂指令的任务。 

* Hugging Face：https://huggingface.co/meituan-longcat/LongCat-Flash-Chat

* Github：https://github.com/meituan-longcat/LongCat-Flash-Chat


**[⬆ 返回README目录](../README.md#目录)**
**[⬆ Back to Contents](../README-EN.md#contents)**
